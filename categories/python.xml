<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>绿萝间 (Python)</title><link>https://muxuezi.github.io/</link><description></description><atom:link type="application/rss+xml" rel="self" href="https://muxuezi.github.io/categories/python.xml"></atom:link><language>en</language><lastBuildDate>Sun, 13 Dec 2015 07:52:15 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>6.Utilizing Parallel Python</title><link>https://muxuezi.github.io/posts/6utilizing-parallel-python.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用Parallel-Python模块"&gt;用Parallel Python模块&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/6utilizing-parallel-python.html#%E7%94%A8Parallel-Python%E6%A8%A1%E5%9D%97"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;上一章我们用&lt;code&gt;multiprocessing&lt;/code&gt;和&lt;code&gt;ProcessPoolExecutor&lt;/code&gt;模块演示了两个例子。这一章我们将介绍命名队列（named pipe）的用法，以及如何用&lt;strong&gt; Parallel Python (PP)&lt;/strong&gt;模块的进程解决问题。&lt;/p&gt;
&lt;p&gt;本章内容包括以下主题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解进程间通信概念&lt;/li&gt;
&lt;li&gt;介绍PP模块&lt;/li&gt;
&lt;li&gt;用PP在SMP架上计算Fibonacci数列&lt;/li&gt;
&lt;li&gt;用PP实现并行网络爬虫&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/6utilizing-parallel-python.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Parallel Programming with Python</category><category>Python</category><guid>https://muxuezi.github.io/posts/6utilizing-parallel-python.html</guid><pubDate>Sat, 03 Oct 2015 04:44:35 GMT</pubDate></item><item><title>5.Using Multiprocessing and ProcessPoolExecutor</title><link>https://muxuezi.github.io/posts/5using-multiprocessing-and-processpoolexecutor.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用multiprocessing和ProcessPoolExecutor模块"&gt;用&lt;code&gt;multiprocessing&lt;/code&gt;和&lt;code&gt;ProcessPoolExecutor&lt;/code&gt;模块&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/5using-multiprocessing-and-processpoolexecutor.html#%E7%94%A8multiprocessing%E5%92%8CProcessPoolExecutor%E6%A8%A1%E5%9D%97"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;上一章我们用&lt;code&gt;threading&lt;/code&gt;模块演示了两个例子。这一章我们将介绍&lt;code&gt;multiprocessing&lt;/code&gt;的用法，实现与&lt;code&gt;threading&lt;/code&gt;类似的接口。但是，我们将用进程范式。&lt;/p&gt;
&lt;p&gt;本章内容包括以下主题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解进程的概念&lt;/li&gt;
&lt;li&gt;理解多进程通信&lt;/li&gt;
&lt;li&gt;用&lt;code&gt;multiprocessing&lt;/code&gt;实现多请求的Fibonacci数列&lt;/li&gt;
&lt;li&gt;用&lt;code&gt;ProcessPoolExecutor&lt;/code&gt;实现并行网络爬虫&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/5using-multiprocessing-and-processpoolexecutor.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Parallel Programming with Python</category><category>Python</category><guid>https://muxuezi.github.io/posts/5using-multiprocessing-and-processpoolexecutor.html</guid><pubDate>Tue, 29 Sep 2015 12:53:28 GMT</pubDate></item><item><title>4.Using the threading and concurrent.futures Modules</title><link>https://muxuezi.github.io/posts/4using-the-threading-and-concurrentfutures-modules.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="4.用threading和concurrent.futures模块"&gt;4.用&lt;code&gt;threading&lt;/code&gt;和&lt;code&gt;concurrent.futures&lt;/code&gt;模块&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/4using-the-threading-and-concurrentfutures-modules.html#4.%E7%94%A8threading%E5%92%8Cconcurrent.futures%E6%A8%A1%E5%9D%97"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在上一章，我们总结了并行思想可以解决的一些问题。这一章，我们将用Python的&lt;code&gt;threading&lt;/code&gt;模块实现每个问题的解决方案。&lt;/p&gt;
&lt;p&gt;本章内容包括以下主题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程的定义&lt;/li&gt;
&lt;li&gt;&lt;code&gt;threading&lt;/code&gt;和&lt;code&gt;_thread&lt;/code&gt;的选择&lt;/li&gt;
&lt;li&gt;用&lt;code&gt;threading&lt;/code&gt;实现多请求的Fibonacci数列&lt;/li&gt;
&lt;li&gt;用&lt;code&gt;concurrent.futures&lt;/code&gt;模块实现网络爬虫&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/4using-the-threading-and-concurrentfutures-modules.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Parallel Programming with Python</category><category>Python</category><guid>https://muxuezi.github.io/posts/4using-the-threading-and-concurrentfutures-modules.html</guid><pubDate>Mon, 28 Sep 2015 12:42:03 GMT</pubDate></item><item><title>2-working-with-linear-models</title><link>https://muxuezi.github.io/posts/2-working-with-linear-models.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="处理线性模型"&gt;处理线性模型&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/2-working-with-linear-models.html#%E5%A4%84%E7%90%86%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本章包括以下主题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/fitting-a-line-through-data.html"&gt;线性回归模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/evaluating-the-linear-regression-model.html"&gt;评估线性回归模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/using-ridge-regression-to-overcome-linear-regression-shortfalls.html"&gt;用岭回归弥补线性回归的不足&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/optimizing-the-ridge-regression-parameter.html"&gt;优化岭回归参数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/using-sparsity-to-regularize-models.html"&gt;LASSO正则化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/taking-a-more-fundamental-approach-to-regularization-with-lars.html"&gt;LARS正则化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/using-linear-methods-for-classification-logistic-regression.html"&gt;用线性方法处理分类问题——逻辑回归&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/directly-applying-bayesian-ridge-regression.html"&gt;贝叶斯岭回归&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muxuezi.github.io/posts/using-boosting-to-learn-from-errors.html"&gt;用梯度提升回归从误差中学习&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/2-working-with-linear-models.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><category>scikit-learn cookbook</category><guid>https://muxuezi.github.io/posts/2-working-with-linear-models.html</guid><pubDate>Tue, 18 Aug 2015 05:07:14 GMT</pubDate></item><item><title>fitting-a-line-through-data</title><link>https://muxuezi.github.io/posts/fitting-a-line-through-data.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="线性回归模型"&gt;线性回归模型&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/fitting-a-line-through-data.html#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;现在，我们来做一些建模！我们从最简单的线性回归（Linear regression）开始。线性回归是最早的也是最基本的模型——把数据拟合成一条直线。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/fitting-a-line-through-data.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><category>scikit-learn cookbook</category><guid>https://muxuezi.github.io/posts/fitting-a-line-through-data.html</guid><pubDate>Tue, 18 Aug 2015 04:57:47 GMT</pubDate></item><item><title>optimizing-the-ridge-regression-parameter</title><link>https://muxuezi.github.io/posts/optimizing-the-ridge-regression-parameter.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="优化岭回归参数"&gt;优化岭回归参数&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/optimizing-the-ridge-regression-parameter.html#%E4%BC%98%E5%8C%96%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%8F%82%E6%95%B0"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;当你使用岭回归模型进行建模时，需要考虑&lt;code&gt;Ridge&lt;/code&gt;的&lt;code&gt;alpha&lt;/code&gt;参数。&lt;/p&gt;
&lt;p&gt;例如，用OLS（普通最小二乘法）做回归也许可以显示两个变量之间的某些关系；但是，当&lt;code&gt;alpha&lt;/code&gt;参数正则化之后，那些关系就会消失。做决策时，这些关系是否需要考虑就显得很重要了。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/optimizing-the-ridge-regression-parameter.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><category>scikit-learn cookbook</category><guid>https://muxuezi.github.io/posts/optimizing-the-ridge-regression-parameter.html</guid><pubDate>Tue, 18 Aug 2015 04:57:47 GMT</pubDate></item><item><title>taking-a-more-fundamental-approach-to-regularization-with-lars</title><link>https://muxuezi.github.io/posts/taking-a-more-fundamental-approach-to-regularization-with-lars.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="LARS正则化"&gt;LARS正则化&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/taking-a-more-fundamental-approach-to-regularization-with-lars.html#LARS%E6%AD%A3%E5%88%99%E5%8C%96"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果斯坦福大学的Bradley Efron, Trevor Hastie, Iain Johnstone和Robert Tibshirani没有发现它的话[1]，LARS(Least Angle Regression，最小角回归)可能有一天会被你想出来，它借用了&lt;a href="https://en.wikipedia.org/wiki/Gilbert_Strang"&gt;威廉·吉尔伯特·斯特朗（William Gilbert Strang）&lt;/a&gt;介绍过的高斯消元法（Gaussian elimination）的灵感。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/taking-a-more-fundamental-approach-to-regularization-with-lars.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><category>scikit-learn cookbook</category><guid>https://muxuezi.github.io/posts/taking-a-more-fundamental-approach-to-regularization-with-lars.html</guid><pubDate>Tue, 18 Aug 2015 04:57:47 GMT</pubDate></item><item><title>directly-applying-bayesian-ridge-regression</title><link>https://muxuezi.github.io/posts/directly-applying-bayesian-ridge-regression.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="贝叶斯岭回归"&gt;贝叶斯岭回归&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/directly-applying-bayesian-ridge-regression.html#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%B2%AD%E5%9B%9E%E5%BD%92"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;em&gt;用岭回归弥补线性回归的不足&lt;/em&gt;主题中，我们介绍了岭回归优化的限制条件。我们还介绍了相关系数的先验概率分布的贝叶斯解释，将很大程度地影响着先验概率分布，先验概率分布通常均值是0。&lt;/p&gt;
&lt;p&gt;因此，现在我们就来演示如何scikit-learn来应用这种解释。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/directly-applying-bayesian-ridge-regression.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><category>scikit-learn cookbook</category><guid>https://muxuezi.github.io/posts/directly-applying-bayesian-ridge-regression.html</guid><pubDate>Tue, 18 Aug 2015 04:57:47 GMT</pubDate></item><item><title>using-sparsity-to-regularize-models</title><link>https://muxuezi.github.io/posts/using-sparsity-to-regularize-models.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="LASSO正则化"&gt;LASSO正则化&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/using-sparsity-to-regularize-models.html#LASSO%E6%AD%A3%E5%88%99%E5%8C%96"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;LASSO（ least absolute shrinkage and selection operator，最小绝对值收缩和选择算子）方法与岭回归和LARS（least angle regression，最小角回归）很类似。与岭回归类似，它也是通过增加惩罚函数来判断、消除特征间的共线性。与LARS相似的是它也可以用作参数选择，通常得出一个相关系数的稀疏向量。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/using-sparsity-to-regularize-models.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><category>scikit-learn cookbook</category><guid>https://muxuezi.github.io/posts/using-sparsity-to-regularize-models.html</guid><pubDate>Tue, 18 Aug 2015 04:57:47 GMT</pubDate></item><item><title>evaluating-the-linear-regression-model</title><link>https://muxuezi.github.io/posts/evaluating-the-linear-regression-model.html</link><dc:creator>Tao Junjie</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="评估线性回归模型"&gt;评估线性回归模型&lt;a class="anchor-link" href="https://muxuezi.github.io/posts/evaluating-the-linear-regression-model.html#%E8%AF%84%E4%BC%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在这个主题中，我们将介绍回归模型拟合数据的效果。上一个主题我们拟合了数据，但是并没太关注拟合的效果。每当拟合工作做完之后，我们应该问的第一个问题就是“拟合的效果如何？”本主题将回答这个问题。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://muxuezi.github.io/posts/evaluating-the-linear-regression-model.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><category>scikit-learn cookbook</category><guid>https://muxuezi.github.io/posts/evaluating-the-linear-regression-model.html</guid><pubDate>Tue, 18 Aug 2015 04:57:47 GMT</pubDate></item></channel></rss>